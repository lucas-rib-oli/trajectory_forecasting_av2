{
  "num_layers": 2,
  "d_model": 128, // the number of expected features in the encoder/decoder inputs
  "nhead": 8, // the number of heads in the multiheadattention models
  "num_encoder_layers": 6, // the number of sub-encoder-layers in the encoder
  "dim_feedforward" : 256, // the dimension of the feedforward network model
  "enc_inp_size" : 2,
  "dec_inp_size" : 2,
  "dec_out_size" : 2,
  "dropout": 0.1,
  "opt_warmup" : 5,
  "opt_factor" : 0.1,
  "num_epochs": 1000,
  "lr": 1e-4,
  "batch_size": 64,
  "sequence_length": 8,
  "num_workers" : 8,
  "device" : "cuda:0",
  "experiment_name" : "transHuberLoss_noamOpt_normData_deltaGlobal_xyz_L2_greedy_val",
  "resume_train" : false
}